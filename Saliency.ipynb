{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('adv_spkr': conda)"
  },
  "interpreter": {
   "hash": "6367eb0ee96bfa9eef11d557d9c922ca9bb552a5adb9aa21b3734f9b36c5c88f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "AUTO_PATH = \"/home/zhengxio/Xingyu/CovidV2/repos/auto/\"\r\n",
    "os.chdir(AUTO_PATH) # Must run at network directory."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from tensorboardX import SummaryWriter\r\n",
    "from tqdm import tqdm\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.optim as optim\r\n",
    "import torch.backends.cudnn as cudnn\r\n",
    "\r\n",
    "from models import resnet\r\n",
    "from models.model import Network\r\n",
    "from utils import set_path, create_logger, save_checkpoint, count_parameters, Genotype\r\n",
    "from config import cfg, update_config\r\n",
    "from utils import set_path, create_logger, save_checkpoint, count_parameters\r\n",
    "from data_objects.DeepSpeakerDataset import DeepSpeakerDataset\r\n",
    "from functions import train_from_scratch, validate_identification\r\n",
    "from loss import CrossEntropyLoss\r\n",
    "from data_objects import audio\r\n",
    "from torchvision import transforms as T\r\n",
    "from data_objects.transforms import Normalize, TimeReverse, generate_test_sequence\r\n",
    "\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import cm\r\n",
    "%matplotlib inline\r\n",
    "import pathlib"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/zhengxio/anaconda3/envs/adv_spkr/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_model(checkpoint_file):\r\n",
    "    model = resnet.resnet34(num_classes=2)\r\n",
    "    checkpoint = torch.load(checkpoint_file)\r\n",
    "    model.load_state_dict(checkpoint['state_dict'])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def draw(file,model,outpath,mean,std):\r\n",
    "    frames = np.load(file)\r\n",
    "    transform = T.Compose([\r\n",
    "            Normalize(mean, std),\r\n",
    "            TimeReverse(),\r\n",
    "        ])\r\n",
    "    input=transform(generate_test_sequence(frames,300))\r\n",
    "    draw_CAM(model,input,frames,outpath,visual_heatmap=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def draw_CAM(model, data, origin_data, save_path, transform=None, visual_heatmap=False):\r\n",
    "    \r\n",
    "    model.eval()\r\n",
    "    t_data=torch.from_numpy(data)\r\n",
    "    features = model.featuremaps(t_data)\r\n",
    "\r\n",
    "    v = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))\r\n",
    "    v = v.view(v.size(0), -1)\r\n",
    "    output = model.classifier(v)\r\n",
    "    output = features\r\n",
    "    \r\n",
    "                                    # In order to be able to read the auxiliary function defined by the intermediate gradient\r\n",
    "    def extract(g):\r\n",
    "        global features_grad\r\n",
    "        features_grad = g\r\n",
    "                                    # Predict the output score corresponding to the category with the highest score\r\n",
    "    pred = torch.argmax(output).item()\r\n",
    "    pred_class = output\r\n",
    " \r\n",
    "    features.register_hook(extract)\r\n",
    "    pred_class.backward(output)     # calculate the gradient\r\n",
    "    grads = features_grad           # Get gradient\r\n",
    " \r\n",
    "    pooled_grads = torch.nn.functional.adaptive_avg_pool2d(grads, (1, 1))\r\n",
    " \r\n",
    "                                    # Here the batch size defaults to 1, so the 0th dimension (batch size dimension) is removed\r\n",
    "    pooled_grads = pooled_grads[0]\r\n",
    "    features = features[0]\r\n",
    "                                    # 512 is the number of channels in the last layer of feature\r\n",
    "    for i in range(512):\r\n",
    "        features[i, ...] *= pooled_grads[i, ...]\r\n",
    " \r\n",
    "                                    # The following parts are implemented with Keras version\r\n",
    "    heatmap = features.detach().numpy()\r\n",
    "    heatmap = np.mean(heatmap, axis=0)\r\n",
    "    heatmap = np.maximum(heatmap, 0)\r\n",
    "    heatmap /= np.max(heatmap)\r\n",
    "\r\n",
    "\r\n",
    "    origin = t_data.detach().numpy()\r\n",
    "    origin = np.mean(origin, axis=0)\r\n",
    "    origin = np.maximum(origin, 0)\r\n",
    "    origin /= np.max(origin)\r\n",
    "\r\n",
    "\r\n",
    "    if visual_heatmap:\r\n",
    "         heatmap=np.rot90(heatmap)\r\n",
    "         plt.matshow(heatmap,cmap=plt.cm.plasma,interpolation='spline16')\r\n",
    "         plt.axis('off')\r\n",
    "         plt.savefig(save_path+\"heat.png\")\r\n",
    "         plt.close()\r\n",
    "         \r\n",
    "         origin=np.rot90(origin)\r\n",
    "         plt.matshow(origin)\r\n",
    "         plt.axis('off')\r\n",
    "         plt.savefig(save_path+\"feat.png\")\r\n",
    "         plt.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "best_models={\r\n",
    "    \"cough\":\"cough_3.pth\",\r\n",
    "    \"speech\":\"speech_1.pth\",\r\n",
    "    \"breathing\":\"breathing_4.pth\"\r\n",
    "}\r\n",
    "\r\n",
    "OUTPUT_PATH=\"/home/zhengxio/Xingyu/Covid_data/feat_and_heat\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def do(Atype):\r\n",
    "    model = get_model('/home/zhengxio/Xingyu/CovidV2/repos/auto/best_models/'+best_models[Atype])\r\n",
    "    features_path = \"/home/zhengxio/Xingyu/CovidV2/repos/auto/saved_data_all_train/{}_0_data\".format(Atype)\r\n",
    "    mean = np.load(features_path+'/mean.npy')\r\n",
    "    std = np.load(features_path+'/std.npy')\r\n",
    "\r\n",
    "\r\n",
    "    def do_class(label):\r\n",
    "        folder = features_path+\"/feature/merged/id{}\".format(label)\r\n",
    "        print(folder)\r\n",
    "        for file in os.listdir(folder):\r\n",
    "            \r\n",
    "            if \".txt\" in file:continue\r\n",
    "            name = file[:int((len(file)-4)/2)]\r\n",
    "            sub = \"origin_\"\r\n",
    "            if \"_\" in name:\r\n",
    "                s = name.split(\"_\")\r\n",
    "                name = s[0]\r\n",
    "                sub = \"aug_\"+s[1]+\"_\"\r\n",
    "       \r\n",
    "            out_path = OUTPUT_PATH+\"/{}/{}/{}/\".format(label,name,Atype)\r\n",
    "            pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\r\n",
    "            out_path+=sub\r\n",
    "            print(out_path.replace(OUTPUT_PATH,\"\"))\r\n",
    "            \r\n",
    "            draw(features_path+\"/feature/merged/id{}/{}\".format(label,file),model,out_path,mean,std)\r\n",
    "            break\r\n",
    "\r\n",
    "    do_class(0)\r\n",
    "    do_class(1)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# draw specific feature\r\n",
    "draw(\"xxx.npy\",loaded_model,\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# draw all features\r\n",
    "for t in [\"breathing\",\"cough\",\"speech\"]:\r\n",
    "    do(t)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}